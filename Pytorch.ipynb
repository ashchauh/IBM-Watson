{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Fetching package metadata .............\nSolving package specifications: .\n\nPackage plan for installation in environment /opt/conda/envs/DSX-Python35:\n\nThe following NEW packages will be INSTALLED:\n\n    cudatoolkit: 8.0-3                                     \n    cudnn:       7.0.5-cuda8.0_0                           \n    pytorch:     0.3.1-py35_cuda8.0.61_cudnn7.0.5_2 pytorch\n    pytorch-cpu: 0.3.1-py35_cpu_2                   pytorch\n    torchvision: 0.2.0-py35heaa392f_1               pytorch\n\ncudatoolkit-8. 100% |################################| Time: 0:00:04  82.52 MB/s\ncudnn-7.0.5-cu 100% |################################| Time: 0:00:07  36.94 MB/s\npytorch-0.3.1- 100% |################################| Time: 0:00:09  22.62 MB/sime: 0:00:02  18.42 MB/sime: 0:00:02  22.02 MB/s\npytorch-cpu-0. 100% |################################| Time: 0:00:01  25.85 MB/sime: 0:00:01  26.11 MB/s\ntorchvision-0. 100% |################################| Time: 0:00:00  50.87 MB/s\n"
                }
            ], 
            "source": "!conda install pytorch-cpu torchvision -c pytorch\n"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import torch"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x2ac7434ebbf0>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "torch.manual_seed(123)"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "m_tensor = torch.randn((6, 3, 28, 28))"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y=m_tensor.size"
        }, 
        {
            "execution_count": 77, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 77, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "\n 1.4417  1.3267\n 0.8776  0.0588\n[torch.FloatTensor of size 2x2]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y"
        }, 
        {
            "execution_count": 78, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data=torch.randn(64000,3,28,28)"
        }, 
        {
            "execution_count": 79, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data_reshaped=data.view(32,-1,3,28,28)"
        }, 
        {
            "execution_count": 80, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 80, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "torch.Size([32, 2000, 3, 28, 28])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "data_reshaped.shape"
        }, 
        {
            "execution_count": 81, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "a=autograd.Variable(torch.Tensor([1,2,3]), requires_grad=True)"
        }, 
        {
            "execution_count": 82, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Variable containing:\n 1\n 2\n 3\n[torch.FloatTensor of size 3]\n\n"
                }
            ], 
            "source": "print(a)"
        }, 
        {
            "execution_count": 83, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "b=autograd.Variable(torch.Tensor([4,5,6]),requires_grad=True)"
        }, 
        {
            "execution_count": 84, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Variable containing:\n 4\n 5\n 6\n[torch.FloatTensor of size 3]\n\n"
                }
            ], 
            "source": "print(b)"
        }, 
        {
            "execution_count": 88, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 88, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "torch.Size([3])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "b.shape"
        }, 
        {
            "execution_count": 86, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "c=a+b"
        }, 
        {
            "execution_count": 87, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n 5\n 7\n 9\n[torch.FloatTensor of size 3]\n\n"
                }
            ], 
            "source": "print(c.data)"
        }, 
        {
            "execution_count": 89, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "operation=c.grad_fn"
        }, 
        {
            "execution_count": 90, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<AddBackward1 object at 0x2ac7881d2e80>\n"
                }
            ], 
            "source": "print(operation)"
        }, 
        {
            "execution_count": 91, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "s=c.sum()"
        }, 
        {
            "execution_count": 92, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<SumBackward0 object at 0x2ac7881d2da0>\n"
                }
            ], 
            "source": "print(s.grad_fn)"
        }, 
        {
            "execution_count": 93, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "s.backward(retain_graph=True)"
        }, 
        {
            "execution_count": 94, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Variable containing:\n 1\n 2\n 3\n[torch.FloatTensor of size 3]\n\nVariable containing:\n 1\n 1\n 1\n[torch.FloatTensor of size 3]\n\nVariable containing:\n 1\n 1\n 1\n[torch.FloatTensor of size 3]\n\n"
                }
            ], 
            "source": "print(a)\nprint(a.grad)\nprint(b.grad)"
        }, 
        {
            "execution_count": 95, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The backward propagation function will update the variables and add the previous one with the current one"
        }, 
        {
            "execution_count": 96, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x=torch.randn((2,2))\ny=torch.randn((2,2))"
        }, 
        {
            "execution_count": 97, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n-2.6978 -0.2450\n-0.5705 -0.9431\n[torch.FloatTensor of size 2x2]\n\n"
                }
            ], 
            "source": "z=x+y\nprint(z)"
        }, 
        {
            "execution_count": 98, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "var_x=autograd.Variable(x,requires_grad=True)\nvar_y=autograd.Variable(y,requires_grad=True)"
        }, 
        {
            "execution_count": 101, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Variable containing:\n-2.6978 -0.2450\n-0.5705 -0.9431\n[torch.FloatTensor of size 2x2]\n\n<AddBackward1 object at 0x2ac7881ae278>\n"
                }
            ], 
            "source": "var_z=var_x+var_y\nprint(var_z)\nprint(var_z.grad_fn)"
        }, 
        {
            "execution_count": 102, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "var_z_data=var_z.data"
        }, 
        {
            "execution_count": 103, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "new_var_z=autograd.Variable(var_z_data)"
        }, 
        {
            "execution_count": 104, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "None\n"
                }
            ], 
            "source": "print(new_var_z.grad_fn)"
        }, 
        {
            "execution_count": 107, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "RuntimeError", 
                    "evalue": "element 0 of variables does not require grad and does not have a grad_fn", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-107-93bad3c65b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_var_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mRuntimeError\u001b[0m: element 0 of variables does not require grad and does not have a grad_fn"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "new_var_z.backward(retain_graph=True)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}